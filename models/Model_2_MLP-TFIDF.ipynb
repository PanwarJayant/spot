{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b6ba52-fb11-43da-bb4f-95d74d1dab06",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0262778-08e2-40fd-98d9-5798d00a17c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import markov\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report, accuracy_score\n",
    "from markov.api.model import ModelRecorder   # importing Model recorder from markov, used for experiment recording\n",
    "from markov.api.recording.experiments.integrations.keras.keras_auto_record import auto_record\n",
    "#from markov.api.recording.integrations.keras.keras_auto_record import auto_record\n",
    "from markov.api.schemas.model_recording import ModelRecordingConfig, SingleTagInferenceRecord\n",
    "import scikitplot as skplt\n",
    "import re\n",
    "import os\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9532500-cc98-4954-9598-8c54568aaf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-plot\n",
      "  Using cached scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: scipy>=0.9 in /opt/conda/lib/python3.9/site-packages (from scikit-plot) (1.9.3)\n",
      "Requirement already satisfied: joblib>=0.10 in /opt/conda/lib/python3.9/site-packages (from scikit-plot) (1.1.1)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from scikit-plot) (3.5.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /opt/conda/lib/python3.9/site-packages (from scikit-plot) (1.2.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (9.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.23.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (22.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.18->scikit-plot) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
      "Installing collected packages: scikit-plot\n",
      "Successfully installed scikit-plot-0.3.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4981e46-914a-4a32-b73e-c2b7041ef878",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(os.path.join(os.path.curdir, \"Datasets\", \"master_dataset.csv\")).fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc4e7593-9194-421b-ba90-150fd8a691f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data1[data1.label_sexist == 'sexist']\n",
    "ndf = data1[data1.label_sexist == 'not sexist']\n",
    "add_df = ndf.sample(2000)\n",
    "frames = [add_df,df]\n",
    "data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0deebf-f656-424a-b419-ff61cdc7ac65",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f50e7b7-7820-4562-9188-c72921a8190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Removes HTML tags and removes punctuation from the text\"\"\"\n",
    "    text = text.lower() #lower case\n",
    "    text = re.sub(r'http\\S+', '', text) # remove http links\n",
    "    text = re.sub(r'www\\S+', '', text)  # remove www website\n",
    "    text = re.sub(r'<.*?>', '', text)  # remove html tags\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # remove special characters like !,@,#,$,%\n",
    "    text = re.sub('\\s+', ' ', text) # replace multiple space by single space\n",
    "    return text\n",
    "\n",
    "def remove_stopword(text, stopwords):\n",
    "    \"\"\"Removes common words such as \"the\" and \"a\" from the text\"\"\"    \n",
    "    return \" \".join([word for word in text.split() if word not in (stop_words)])\n",
    "  \n",
    "def lemma_text(text, lemmatizer):\n",
    "    \"\"\"Reduces words to their base forms using lemmatization\"\"\"\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in tokenize(text)]\n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "def stem_text(text, stemmer):\n",
    "    \"\"\"Reduces words to their base forms using the provided stemmer\"\"\"\n",
    "    stemmed_words = [stemmer.stem(word) for word in tokenize(text)]\n",
    "    return \" \".join(stemmed_words)\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Splits the text into individual words\"\"\"\n",
    "    return text.split()\n",
    "\n",
    "def process_text(text, lemmatizer, stemmer, stop_words):\n",
    "    text = clean_text(text)\n",
    "    text = remove_stopword(text, stop_words)\n",
    "    #text = lemma_text(text, lemmatizer)\n",
    "    #text = stem_text(text, stemmer)\n",
    "    return text #tokenize(text) #START_TOKEN + \" \".join(tokenize(text)) + STOP_TOKEN\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66c33b01-23c3-45bc-8014-793e5f3139fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_sexist</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9180</th>\n",
       "      <td>Nobody cares about height if you are taller th...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>nobody cares height taller girl thats enough f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18640</th>\n",
       "      <td>More people would favor the womenâ€™s movement i...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>people would favor womens movement knew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18861</th>\n",
       "      <td>MENTION4248 MENTION2511 i love those too much....</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>mention4248 mention2511 love much much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10798</th>\n",
       "      <td>Ive watched a couple of her videos, and she's ...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>ive watched couple videos shes kind depressing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>Not even getting into genders Does he realize ...</td>\n",
       "      <td>not sexist</td>\n",
       "      <td>even getting genders realize even amongst anim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label_sexist  \\\n",
       "9180   Nobody cares about height if you are taller th...   not sexist   \n",
       "18640  More people would favor the womenâ€™s movement i...   not sexist   \n",
       "18861  MENTION4248 MENTION2511 i love those too much....   not sexist   \n",
       "10798  Ive watched a couple of her videos, and she's ...   not sexist   \n",
       "3979   Not even getting into genders Does he realize ...   not sexist   \n",
       "\n",
       "                                          processed_text  \n",
       "9180   nobody cares height taller girl thats enough f...  \n",
       "18640            people would favor womens movement knew  \n",
       "18861             mention4248 mention2511 love much much  \n",
       "10798  ive watched couple videos shes kind depressing...  \n",
       "3979   even getting genders realize even amongst anim...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stores the result in a new column called 'processed_text'\n",
    "data[\"processed_text\"] = data['text'].apply(process_text, lemmatizer = lemmatizer, stemmer = stemmer, stop_words = stop_words)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d20a8280-2a47-4ce7-b5ad-9dde5aca7875",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(data['processed_text'], data['label_sexist'],stratify=data['label_sexist'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "864e98f0-63e3-4384-bb07-01f783238a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [str(i).split('/') for i in train_Y]\n",
    "text= train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91397281-58ad-4d39-b0fa-8e3745332d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The code creates a Tf-idf vectorizer with a minimum document frequency of 5, \n",
    "applies it to a list of texts, then creates a multilabel binarizer and \n",
    "fits it to a list of labels. It creates arrays for the input and output features, and \n",
    "splits the data into training and test sets\"\"\"\n",
    "\n",
    "tfidfvectorizer = TfidfVectorizer(min_df = 5) #max_features=3000\n",
    "x_tfidf = tfidfvectorizer.fit_transform(text).toarray()\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(labels)\n",
    "Y = mlb.transform(labels)\n",
    "n_op_features = len(Y[0])\n",
    "train_x,test_x,train_y,test_y = train_test_split(x_tfidf,Y,test_size=0.2)\n",
    "n_ip_features = len(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3dc81a2-71ef-419f-9382-19fbb83bdd7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1549fda-e8b6-4eaa-aae3-d8e28fb673c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
